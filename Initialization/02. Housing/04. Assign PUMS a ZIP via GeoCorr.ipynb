{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16e2d097-f3c0-4230-ab21-f7855f9dc294",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Assign PUMS a ZIP via GeoCorr\n",
    "\n",
    "\n",
    "## Purpose\n",
    "\n",
    "I hope to accomplish the following:\n",
    "<p></p>\n",
    "\n",
    "* assign a zip code to each PUMS (wrangled) record\n",
    "\n",
    "Each wrangled PUMS record, representing an individual house, contains a PUMA.\n",
    "In order to assign a realistic street & address to each record, we will need to have an associated zip code.\n",
    "\n",
    "We can link PUMA to ZIP via a Geocorr (see instructions below).\n",
    "We hope to assign zip codes to PUMAs based on this mapping.\n",
    "Because some zip codes contain drastically more houses than others, we use the number of houses within a zip code & PUMA combination to assign probabalistic weight to each zip code contained within a PUMA.\n",
    "\n",
    "-------------------------\n",
    "\n",
    "<b>Ensure that you have already accomplished the following before running the script.</b>\n",
    "<p></p>\n",
    "\n",
    "1. Navigate to the [Geocorr website](https://mcdc.missouri.edu/applications/geocorr2022.html)\n",
    "2. Select State you wish to link to (ex: Washington) \n",
    "3. Select at least 1 source geography \n",
    "   * Other Geographies > PUMA (2012)\n",
    "4. Select at least 1 target geography.  CTRL+click for multiple \n",
    "   * 2020 Geographies > ZIP/ZCTA  \n",
    "5. Select weighting variable of <b>\"Housing units (2020 Census)\"</b>\n",
    "5. Generate output \n",
    "6. Click on .csv link to download\n",
    "7. Save/move output as: \n",
    "   * \"{root_directory}/SupportingDocs/Housing/01_Raw/GeoCorr_mapping<b>_hus</b>.csv\"\n",
    "   \n",
    "### ALSO DO THIS, note the difference bolded\n",
    "\n",
    "1. Navigate to the [Geocorr website](https://mcdc.missouri.edu/applications/geocorr2022.html)\n",
    "2. Select State you wish to link to (ex: Washington) \n",
    "3. Select at least 1 source geography \n",
    "   * Other Geographies > PUMA (2012)\n",
    "4. Select at least 1 target geography.  CTRL+click for multiple \n",
    "   * 2020 Geographies > ZIP/ZCTA  \n",
    "5. Select weighting variable of <b>\"Population (2020 Census)\"</b>\n",
    "5. Generate output \n",
    "6. Click on .csv link to download\n",
    "7. Save/move output as: \n",
    "   * \"{root_directory}/SupportingDocs/Housing/01_Raw/GeoCorr_mapping<b>_pop</b>.csv\"\n",
    "\n",
    "----------------------\n",
    "\n",
    "<p>Author: PJ Gibson</p>\n",
    "<p>Create Date: 2022-07-03</p>\n",
    "<p>Contact: peter.gibson@doh.wa.gov</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41d96abe-e147-4ad8-a5cc-419604175044",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## 1.  Load in variables, libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11ce15d6-1696-4ca7-856f-df3436a24e1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed\n",
    "rng = np.random.default_rng( 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0053122c-7cff-43ea-996e-28ace394051f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2.  Read & Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e67acf6-8706-4aa2-97f1-714eb4fe7682",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.1 PUMS\n",
    "\n",
    "This data has been wrangled so that each row represents and individual house.\n",
    "Each record (row) contains information on the house type, number bedrooms, and many other relevant fields.\n",
    "\n",
    "Most importantly for this script, each record has an associated PUMA.\n",
    "A PUMA represents a geographical area.\n",
    "Depending on the type of census survey you use to pull the PUMS data, PUMAs can represent different population sizes.\n",
    "For the 2019 ACS 5-year survey for Washington State, each PUMA contains anywhere between 40205 - 46959 housing units.\n",
    "<p></p>\n",
    "* More information on PUMS / the PUMA field [linked here](https://www.census.gov/content/dam/Census/library/publications/2021/acs/acs_pums_handbook_2021.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a8990ee-fe1f-4ab8-aa20-0e18d4d5f01c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read in our data\n",
    "df_PUMS_housing = pd.read_csv(f'../../SupportingDocs/Housing/02_Wrangled/PUMS_housing_1to1.csv')\n",
    "\n",
    "# Convert PUMA to string\n",
    "df_PUMS_housing['PUMA'] = df_PUMS_housing['PUMA'].astype(str).str.zfill(5)\n",
    "\n",
    "# Sort by PUMA\n",
    "df_PUMS_housing = df_PUMS_housing.sort_values(['PUMA', 'house_id'], ascending=True).reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80bb24fe-7f3a-4386-94ac-5783e1cc17ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2.2 Geocorr\n",
    "\n",
    "This data has been wrangled so that each row represents and individual house.\n",
    "Each record (row) contains information on the house type, number bedrooms, and many other relevant fields.\n",
    "\n",
    "Most importantly for this script, each record has an associated PUMA.\n",
    "A PUMA represents a geographical area.\n",
    "Depending on the type of census survey you use to pull the PUMS data, PUMAs can represent different population sizes.\n",
    "For the 2019 ACS 5-year survey for Washington State, each PUMA contains anywhere between 40205 - 46959 housing units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdbea937-8f3a-447e-bf40-b29d02d6d883",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read in our dataset\n",
    "df_Geocorr = pd.read_csv(f'../../SupportingDocs/Housing/01_Raw/GeoCorr_mapping_hus.csv')\\\n",
    "               .query('zcta != \" \"')\n",
    "\n",
    "# Koalas has no \"skiprows\" parameter so we need to do this manually\n",
    "df_Geocorr = df_Geocorr[1:].reset_index()\n",
    "\n",
    "# Convert afact to float\n",
    "df_Geocorr['afact'] = df_Geocorr['afact'].astype('float64')\n",
    "\n",
    "# Make number of houses in zip an integer\n",
    "df_Geocorr['hus20'] = df_Geocorr['hus20'].astype(int)\n",
    "\n",
    "# Remove records with no houses\n",
    "df_Geocorr = df_Geocorr.query('hus20 > 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91b7ca1f-ca23-491f-aa83-e499a38ccfa6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Wrangle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e448b7cc-4d9d-4ff6-988b-59d25a36f876",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3.1 Assign weighted probabilities\n",
    "\n",
    "We group by each PUMA to see a list of all available ZIPs within a PUMA.\n",
    "Using the housing counts from each ZIP code and the sum of these counts for all ZIP codes within the PUMA, we can get weights summing to 1.\n",
    "\n",
    "We should be aware that since some ZIPs overlap with multiple PUMAs, that this approach is not perfect.\n",
    "It may result in overestimates for highly populated areas & underestimates for sparsly populated areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba91098f-346f-4c3a-ba82-2bf0964f4074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def normalize_afact(x):\n",
    "  '''\n",
    "  Returns a column with probabilities that sum to 1\n",
    "  \n",
    "  This function is necissary because we utilize a np.choice() function that requires a \"p\" parameter of probabilities that MUST sum to 1.\n",
    "  The current afact values mostly sum to 1, but occasionally are just above or below 1.\n",
    "  We need them perfectly normalized.\n",
    "  \n",
    "  Args:\n",
    "    x (koalas Series): afact values of float type\n",
    "    \n",
    "  Returns:\n",
    "    koalas Series: of length equal to input \"x\" containing values that do sum to 1\n",
    "  '''\n",
    "  \n",
    "  return x / np.sum(x)\n",
    "\n",
    "# enact our normalization within \n",
    "df_Geocorr['proba_zip_within_puma'] = df_Geocorr['hus20'].groupby(df_Geocorr['puma12']).apply(normalize_afact).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d66626d-71a5-46da-866f-dc25b6703f11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Assign ZIP codes to PUMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "889f87ac-9b63-4e7b-885b-a35899edd3e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.1 Compile ZIPs\n",
    "\n",
    "For each PUMS record row, we can use the PUMA-ZIP mapping & corresponding probabalistic weights to randomly select a zip code.\n",
    "Initially I wanted to approach this problem on a record-by record case, but that proved to be inefficient and problematic.\n",
    "I was using numpy.random.choice and kept experiencing an error where my probabilities did not sum to *exactly* 1.  \n",
    "Sumns were off by 0.0000000001 or less.\n",
    "The solution was using the [numpy.random.multinomial](https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html) function.  \n",
    "It has a built in method of making probabilities sum to 1 as long as they're very close.\n",
    "By aggregating to PUMA and using this function, I could randomly assign a zip code to each row containing the specified PUMA.\n",
    "This approach is vectorized and therefore reasonably efficient in my eyes.\n",
    "\n",
    "See code comments below for more detailed view of the methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3ae8b92-074c-407d-b5d2-c3f0a680ff6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We'll loop through each PUMA in order of ascending values\n",
    "list_pumas_sorted_asc = pd.Series(df_Geocorr.puma12.unique()).sort_values().to_numpy()\n",
    "\n",
    "# Filter exclusively to PUMAs found in our 1:1 file\n",
    "list_pumas_sorted_asc = np.array(list(set(list(list_pumas_sorted_asc)) & set(list(df_PUMS_housing.PUMA.unique()))))\n",
    "\n",
    "# Get empty list to append to\n",
    "list_assigned_zips = []\n",
    "\n",
    "# For each puma....\n",
    "for puma in list_pumas_sorted_asc:\n",
    "  \n",
    "  # See how many houses we will need to assign a zip code to\n",
    "  num_applied_houses = len( df_PUMS_housing.query(f'PUMA == \"{puma}\"') )\n",
    "  \n",
    "  # Find out supporting geography, house count by zip information for our puma \n",
    "  df_puma_specific_geographies = df_Geocorr.query(f'puma12 == \"{puma}\"')\n",
    "  df_puma_specific_geographies = df_puma_specific_geographies.sort_values('zcta', ascending=True)\n",
    "  \n",
    "  # Get list of zip codes & their associated probabilities for our puma\n",
    "  list_available_zips = df_puma_specific_geographies['zcta'].to_numpy()\n",
    "  list_available_probs = df_puma_specific_geographies['proba_zip_within_puma'].to_numpy()\n",
    "  \n",
    "  # For each house (within PUMS) with our specified puma, use our probabilities to see which choice our random number generator makes.  Convert to bool\n",
    "  df_random_choices = rng.multinomial( 1 , pvals = list_available_probs , size = num_applied_houses)\n",
    "  df_random_choices = df_random_choices.astype(bool)\n",
    "  \n",
    "  # For each house (row in our random output)...\n",
    "  for i in np.arange(0,len(df_random_choices)):\n",
    "    \n",
    "    # ...append the related zip code that was chosen to our formerly initialized list\n",
    "    list_assigned_zips.append( [puma, list_available_zips[df_random_choices[i]][0]] )\n",
    "    \n",
    "# # Format into pandas dataframe with proper columns\n",
    "df_assigned_zips = pd.DataFrame(list_assigned_zips, columns=['PUMA','assigned_zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b2b3e8b-b9c2-4c28-8ab6-e32f9be5c108",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4.2 Join ZIP codes to PUMS\n",
    "\n",
    "Our output is exactly the same size as our PUMS dataset.\n",
    "Both are ordered by ascending PUMA.\n",
    "We probably could just assign the new ZIP assignments as a new column, but I decided to join them via a merge statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b2bd269-e3c2-41d4-aaa1-5c230666d8d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compile a \"link_ID\" that we will use to join the datasets - group by PUMA and rank by zip/house_id\n",
    "df_assigned_zips['link_id'] = df_assigned_zips.groupby('PUMA')['assigned_zip'].rank('first')\n",
    "df_PUMS_housing['link_id'] = df_PUMS_housing.groupby('PUMA')['house_id'].rank('first')\n",
    "\n",
    "\n",
    "# Join the data together\n",
    "df_PUMS_with_ZIP = df_PUMS_housing.merge(df_assigned_zips, how = 'inner', on = ['PUMA','link_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "890e9a17-df17-475d-8540-ff7a8b58d7eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2326fd6f-6d21-40dc-84c5-6af42a79968a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_PUMS_with_ZIP.to_csv(f'../../SupportingDocs/Housing/03_Complete/PUMS_with_zip.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "319b16a2-9785-4588-a473-4893c3b0fc4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04. Assign PUMS a ZIP via GeoCorr",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

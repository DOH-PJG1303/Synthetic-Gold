# Databricks notebook source
# MAGIC %md
# MAGIC
# MAGIC # State Management Functions
# MAGIC
# MAGIC The purpose of this script is to contain all of the state management related functions for our process
# MAGIC
# MAGIC -------------
# MAGIC
# MAGIC Author(s): PJ Gibson
# MAGIC
# MAGIC Create Date: 2023-01-26
# MAGIC
# MAGIC Last Updated Date: 2023-01-26

# COMMAND ----------

import pyspark.sql.functions as F

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ## 1. createStateTable()

# COMMAND ----------

def createStateTable(path: str, tableNames: list, tablePaths: list):
  '''
  A function to initialize a delta table to track the state of specific delta tables (all or a subset of tables).
  This function is intended to track the state of multiple tables at one time rather than the state of a single
  table. The state of a single table can be handled through the delta table functionality itself. This function
  is a precursor to the logState and setState functions.
  
  Note: The state of a table is defined as the version of the last logged state. This funciton uses -999 as the
    initial state since the state of the tables hasn't been set yet.
  
  Args:
    path (str): A path to store the state table to.
    tableNames (list): A list of table names, these names will be the columns of the state table.
    tablePaths (list): A list of table paths, these will be stored using the names of the table names + 'Path'.
    
  WARNING:
    Table names and paths must be the same length and the table name and path should be located at identical indicies.
    
  Returns:
    None
  '''
    
  stateTable = spark.createDataFrame([{**{tableName: -999 for tableName in tableNames}, 
                                       **{f'{tableName}_path': tablePath for tableName, tablePath in zip(tableNames, tablePaths)}}])
   
  allColumns = tableNames + [f'{tableName}_path' for tableName in tableNames] # produce an ordered set of column names
  allColumns.insert(0, 'state_id') # include an id column for tracking state
  allColumns.insert(1, 'upcoming_year') # include a year column for reverting to a specific year
  
  stateTable = stateTable.withColumn('upcoming_year', F.lit(0))\
    .withColumn('upcoming_year', F.col('upcoming_year').cast(IntegerType()))\
    .withColumn('state_id', F.lit(0))\
    .select(allColumns) # ensure ordering, dictionaries do not guarantee an order

  try:
    stateTable.write.format('delta').save(path)
  except Exception as e:
    print(e)
    
  return None   

print("createStateTable(path: str, tableNames: list, tablePaths: list) :  A function to initialize a delta table to track the state of specific delta tables (all or a subset of tables)")

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ## 2. logState()

# COMMAND ----------

def logState(path: str, upcoming_year: int):
  '''
  Log the state of all tables included in a given state table (as indicated by the path argument)
  with a specified upcoming_year to make it clear where the state was logged out at in the process.
  
  Args:
    path (str): Path to log state to. (state table generated by createStateTable)
    upcoming_year (int): An integer of the year value that proceeds the year of the simulation that was just run.
        * note that if you logstate at the end of the year 1920, you should save it as year = 1921, so when you revert to 1921 and subsequently run the process for the year 1921 it will run as expected.
    
  Returns:
    None
  '''
  stateTable = spark.read.format('delta').load(path) 
  
  # prepare the table names, use the state table to fetch the tableNames, drop anything that isn't a table name
  tableNames = stateTable.columns
  tableNames = [tableName for tableName in tableNames if tableName not in ['upcoming_year', 'state_id']]
  tableNames = [tableName for tableName in tableNames if not tableName.endswith('_path')]

  tableUpdates = {tableName: None for tableName in tableNames}
  
  # fetch current version of all tables in stateTable
  for tableName in tableNames:
    # note the table path so we can propogate that forward
    tablePath = stateTable.select(F.col(f'{tableName}_path')).limit(1).collect()[0][0]
    tableUpdates[f'{tableName}_path'] = tablePath
    
    # obtain the most recent version from each table
    mostRecentVersion = DeltaTable.forPath(spark, tablePath)\
      .history()\
      .select(F.max(F.col('version'))).collect()[0][0]
    
    tableUpdates[tableName] = mostRecentVersion
  
  # include ancillary columns
  tableUpdates['upcoming_year'] = upcoming_year
  tableUpdates['state_id'] = int(stateTable.select(F.max(F.col('state_id'))).collect()[0][0] + 1)

  tableUpdates = spark.createDataFrame([tableUpdates])\
    .withColumn('state_id', F.col('state_id').cast(IntegerType()))\
    .withColumn('upcoming_year', F.col('upcoming_year').cast(IntegerType()))\
    .select(stateTable.columns) # guarantee the ordering is identical
  
  stateTable.union(tableUpdates).write.format('delta').mode('overwrite').save(path)
  
  return None

print("logState(path: str, upcoming_year: int) :  Log the state of all tables included in a given state table (as indicated by the path argument) with relevant annotations")

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ## 3. revertState()

# COMMAND ----------

def revertState(path: str, upcoming_year: int = None):
  '''
  This function takes the path of the state table created by the createStateTable function and
  will roll all associated tables back to a specific version associated with one of the years of the simulation specified by the user.
  
  The result of this process is logged in the state table so that this operation can be undone if necessary.
  
  Args:
    path (str): Path to log state to. (state table generated by createStateTable)
    upcoming_year (int): The desired state (defined in the state table) to rollback to. This argument defaults to None so the user is forced to specify one
      - if upcoming_year = None, raise error
      - elif upcoming_year = -1, all tables reverted to their most recently logged state
      - elif upcoming_year = 2000, all tables reverted to versions logged in the stateMangementTable when upcoming_year = 2000.
      
      *if the upcoming_year that a user specifies has yet to be logged, it will also raise an error
      
  Return:
    None
  '''
  # Read in state table
  stateTable = spark.read.format('delta').load(path) 
    
  if upcoming_year is None:
    raise Exception('You must specify an upcoming_year parameter to use the revertState() function.')
  
  elif upcoming_year == -1: 
    currentStateId = int(stateTable.select(F.max(F.col('state_id'))).collect()[0][0])
    prevState = stateTable.filter(F.col('state_id') == currentStateId)
    
  # else get the most recent 
  else:
    prevState = stateTable.filter(F.col('upcoming_year') == upcoming_year)
    
    if prevState.count() == 0:
      currentStateId = int(stateTable.select(F.max(F.col('state_id'))).collect()[0][0])
      current_year = int(stateTable.filter(F.col('state_id') == currentStateId).select(F.max(F.col('upcoming_year'))).collect()[0][0])
      raise Exception(f'Please specify a year, most recent version saved under upcoming_year = {current_year}')
      
    else:
      prevState = prevState.withColumn('row_id', F.row_number().over(Window.partitionBy(F.lit(1)).orderBy(F.desc('state_id'))))\
                           .filter('row_id == 1')\
                           .drop('row_id')

  # prepare the table names, use the state table to fetch the tableNames, drop anything that isn't a table name
  tableNames = stateTable.columns
  tableNames = [tableName for tableName in tableNames if tableName not in ['upcoming_year', 'state_id']]
  tableNames = [tableName for tableName in tableNames if not tableName.endswith('_path')]
  
  tablesToRollback = 0 # track the number of
  
  for tableName in tableNames:
    tablePath = prevState.select(F.col(f'{tableName}_path')).collect()[0][0]
    prevStateVersion = prevState.select(F.col(tableName)).collect()[0][0]
    
    # check the table's current version to see if any changes are necessary.
    tableReportedVersion = DeltaTable.forPath(spark, tablePath)\
                                     .history()\
                                     .select(F.max(F.col('version'))).collect()[0][0]
    
    if prevStateVersion == tableReportedVersion:
      print(f'No rollback necessary for {tableName} at {tablePath}.')
    else:
      tablesToRollback += 1
      DeltaTable.forPath(spark, tablePath)\
                .restoreToVersion(prevStateVersion)
  
  if tablesToRollback != 0:
    print(f'{tablesToRollback} table(s) were rolled back to upcoming_year = {upcoming_year}. Logging state now . . .')
    logState(path=path, upcoming_year=upcoming_year)
  else:
    print('No rollbacks required, the current state is sufficient.')
  
  return None

print("resetState(path: str, upcoming_year: int = None) : roll all associated tables back to the last known good version (-1) or to specified state_id as found in the state table ")

# COMMAND ----------

# MAGIC %md
# MAGIC
# MAGIC ## 4. includeState()

# COMMAND ----------

def includeState(path: str, tableNames: list, tablePaths: list):
  '''
  After the state management table has been instantiated, it may be necessary to track the state of additional tables.
  This function makes it simple to add another delta table to the state management table.
  
  Args:
    path (str): The path to the state management table (instantiated with createStateTable).
    tableNames (list): A list of table names to begin tracking, these names will be the columns of the state table.
    tablePaths (list): A list of table paths to begin tracking, these will be stored using the names of the table names + 'Path'.
    
  WARNING:
    Table names and paths must be the same length and the table name and path should be located at identical indicies.
    
  Returns:
    None
  '''
  
  stateTable = spark.read.format('delta').load(path)
  currentStateId = int(stateTable.select(F.max(F.col('state_id'))).collect()[0][0])
  most_recent_year = int(stateTable.filter(F.col('state_id') == currentStateId).select(F.max(F.col('upcoming_year'))).collect()[0][0])
  
  stateTableCols = stateTable.columns
  for tableName, tablePath in zip(tableNames, tablePaths):
    # locate the index to insert the table name and the table path, this will guarantee a consistent column ordering in the state management table.  
    pathCols = [i for i, col in enumerate(stateTableCols) if '_path' in col] # re-evaluate each time to keep ordering consistent
    
    # NOTE: insert shifts the existing element at that location one to the right
    stateTableCols.insert(pathCols[0], tableName) # insert the tableName just before the first _path column
    stateTableCols.insert(pathCols[-1] + 2, f'{tableName}_path') # insert the tablePath just after the last _path column, +2 to account for the previous insertion
    
    # fetch the desired table's current version for insertion
    tableReportedVersion = DeltaTable.forPath(spark, tablePath)\
                                     .history()\
                                     .select(F.max(F.col('version'))).collect()[0][0]
    
    # initialize state and path for the additional table
    stateTable = stateTable.withColumn(f'{tableName}', F.lit(tableReportedVersion))\
                           .withColumn(f'{tableName}', F.col(f'{tableName}').cast(LongType()))\
                           .withColumn(f'{tableName}_path', F.lit(tablePath))
    
    print(f'{tableName} has been added to the state management table with version #{tableReportedVersion}.')
   

  stateTable = stateTable.select(stateTableCols) # enforce the desired ordering
  stateTable.write.format('delta').mode('overwrite').option('overwriteSchema', 'true').save(path)

  logState(path=path, upcoming_year=most_recent_year) # log out the state to track when in the history the insertion occurred
  
  return None    

print("includeState(path: str, tableNames: list, tablePaths: list) : A function for including new tables to track in the state management table.")
